# Nano-VTLA API éƒ¨ç½²æŒ‡å—

FastAPI æœåŠ¡éƒ¨ç½²ï¼Œä¾›è¿œç¨‹ä»¿çœŸå®¹å™¨è°ƒç”¨

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1ï¸âƒ£ å®‰è£…ä¾èµ–

```bash
# åœ¨å®¹å™¨å†…
pip install fastapi uvicorn python-multipart
```

### 2ï¸âƒ£ å¯åŠ¨æœåŠ¡

```bash
# åœ¨å®¹å™¨å†…
cd /workspace/nanoLLaVA
python serve_vtla_api.py
```

**è¾“å‡º**ï¼š
```
================================================================================
Nano-VTLA FastAPI Service
================================================================================
Checkpoint: ./outputs/nano_vtla_baseline/checkpoint_step70000.pt
Model: BAAI/Bunny-v1_0-2B-zh
Device: cuda
Dtype: BF16
================================================================================

Starting server on http://0.0.0.0:8000
API æ–‡æ¡£: http://0.0.0.0:8000/docs
================================================================================

Loading Nano-VTLA Model...
âœ… Model Ready for Inference
INFO:     Started server process [1234]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 3ï¸âƒ£ æµ‹è¯•æœåŠ¡

**åœ¨å¦ä¸€ä¸ªç»ˆç«¯**ï¼ˆå®¹å™¨å†…æˆ–å®¿ä¸»æœºï¼‰ï¼š

```bash
# æµ‹è¯•å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# è¿è¡Œå®Œæ•´æµ‹è¯•
python test_vtla_api.py
```

## ğŸ“¡ API æ–‡æ¡£

### Endpoint 1: `/predict` (POST)

**é¢„æµ‹ 7-DoF æœºå™¨äººåŠ¨ä½œ**

**è¾“å…¥**ï¼š
- `image` (File): RGB å›¾åƒæ–‡ä»¶
- `instruction` (String, optional): è¯­è¨€æŒ‡ä»¤
- `use_dummy_tactile` (Boolean, default=True): æ˜¯å¦ä½¿ç”¨ dummy è§¦è§‰

**è¾“å‡º**ï¼š
```json
{
  "success": true,
  "action": [0.0015, 0.0024, -0.0012, 0.0018, 0.0032, -0.0015, 0.1295],
  "action_breakdown": {
    "translation": {
      "dx": 0.0015,
      "dy": 0.0024,
      "dz": -0.0012,
      "unit": "meters"
    },
    "rotation": {
      "droll": 0.0018,
      "dpitch": 0.0032,
      "dyaw": -0.0015,
      "unit": "radians"
    },
    "gripper": {
      "value": 0.1295,
      "range": "0 (open) to 1 (closed)"
    }
  },
  "metadata": {
    "instruction": "Pick up the red cube",
    "image_size": [640, 480],
    "used_dummy_tactile": true
  }
}
```

### Endpoint 2: `/health` (GET)

**æ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€**

**è¾“å‡º**ï¼š
```json
{
  "status": "healthy",
  "model_loaded": true,
  "cuda_available": true,
  "gpu_memory": "8.23 GB"
}
```

### Endpoint 3: `/stats` (GET)

**è·å–åŠ¨ä½œå½’ä¸€åŒ–ç»Ÿè®¡**

**è¾“å‡º**ï¼š
```json
{
  "mean": [-5.6e-06, 1.7e-05, 4.0e-05, -5.5e-05, -2.4e-04, -9.5e-05, 0.1132],
  "std": [0.005, 0.0066, 0.0068, 0.0136, 0.0172, 0.0182, 0.021],
  "description": {
    "0-2": "translation (dx, dy, dz) in meters",
    "3-5": "rotation (droll, dpitch, dyaw) in radians",
    "6": "gripper (0=open, 1=closed)"
  }
}
```

## ğŸ Python å®¢æˆ·ç«¯ç¤ºä¾‹

```python
import requests
from PIL import Image

# 1. åŠ è½½å›¾åƒ
image = Image.open("robot_view.png")

# 2. å‘é€è¯·æ±‚
files = {'image': open("robot_view.png", 'rb')}
data = {
    'instruction': "Pick up the red block",
    'use_dummy_tactile': True
}

response = requests.post("http://localhost:8000/predict", files=files, data=data)
result = response.json()

# 3. è·å–åŠ¨ä½œ
if result['success']:
    action = result['action']
    print(f"Action: {action}")
    
    # æå–åˆ†é‡
    dx, dy, dz = action[0:3]  # å¹³ç§» (ç±³)
    droll, dpitch, dyaw = action[3:6]  # æ—‹è½¬ (å¼§åº¦)
    gripper = action[6]  # å¤¹çˆª (0-1)
    
    # å‘é€ç»™ä»¿çœŸå™¨æ‰§è¡Œ...
```

## ğŸ”Œ ä¸ä»¿çœŸå®¹å™¨é›†æˆ

### æ–¹æ¡ˆ 1: Docker ç½‘ç»œ

```bash
# åˆ›å»º Docker ç½‘ç»œ
docker network create vtla-network

# å¯åŠ¨ VTLA æœåŠ¡å®¹å™¨ï¼ˆåŠ å…¥ç½‘ç»œï¼‰
docker run ... --network vtla-network --name vtla-service ...

# å¯åŠ¨ä»¿çœŸå®¹å™¨ï¼ˆåŠ å…¥åŒä¸€ç½‘ç»œï¼‰
docker run ... --network vtla-network --name sim-container ...

# åœ¨ä»¿çœŸå®¹å™¨å†…è°ƒç”¨
curl http://vtla-service:8000/predict ...
```

### æ–¹æ¡ˆ 2: Host ç½‘ç»œ

```bash
# VTLA æœåŠ¡ä½¿ç”¨ host ç½‘ç»œï¼ˆå·²é…ç½®ï¼‰
docker run ... --net=host ...

# ä»¿çœŸå®¹å™¨ä¹Ÿä½¿ç”¨ host ç½‘ç»œ
docker run ... --net=host ...

# ä¸¤è€…éƒ½å¯ä»¥é€šè¿‡ localhost:8000 é€šä¿¡
```

## ğŸ›¡ï¸ æ€§èƒ½ & ä¼˜åŒ–

**æ¨ç†é€Ÿåº¦**ï¼š
- å•æ¬¡é¢„æµ‹: ~150ms (åŒ…å«å›¾åƒé¢„å¤„ç†)
- ååé‡: ~6-7 requests/s

**æ˜¾å­˜å ç”¨**ï¼š
- æ¨¡å‹: ~8GB
- æ¨ç†: ~1GB (ä¸´æ—¶)
- æ€»è®¡: ~9GB (11GB GPU è¶³å¤Ÿ)

**ä¼˜åŒ–å»ºè®®**ï¼š
- æ‰¹é‡é¢„æµ‹ï¼šä¸€æ¬¡å¤„ç†å¤šä¸ªå›¾åƒ
- æ¨¡å‹é‡åŒ–ï¼šä½¿ç”¨ INT8 å‡å°‘æ˜¾å­˜
- TensorRTï¼šåŠ é€Ÿæ¨ç†

## ğŸ“Š ç›‘æ§

```bash
# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
curl http://localhost:8000/health

# æŸ¥çœ‹è¯·æ±‚æ—¥å¿—
# æœåŠ¡ä¼šå®æ—¶æ‰“å°æ¯ä¸ªè¯·æ±‚çš„ä¿¡æ¯
```

## ğŸ› æ•…éšœæ’é™¤

### Q: ModuleNotFoundError: No module named 'fastapi'
```bash
pip install fastapi uvicorn python-multipart
```

### Q: CUDA out of memory
å‡å°æ¨¡å‹æ˜¾å­˜æˆ–å…³é—­å…¶ä»– GPU ç¨‹åº

### Q: è¿æ¥æ‹’ç»
æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯åŠ¨ï¼š`curl http://localhost:8000/health`

---

**éƒ¨ç½²å®Œæˆåï¼Œä»¿çœŸå®¹å™¨å°±å¯ä»¥è°ƒç”¨ API è·å–åŠ¨ä½œäº†ï¼** ğŸš€
